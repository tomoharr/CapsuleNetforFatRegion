[Atomoharu@tensorflow-1-vm:~/forGCE$ python3 main.py --data_root_dir ./ct --split_num 1 --net segcapsr3 --train 1 --test 0 --manip 0 --savefix valaug_ --which_gpus -1 --gpus 1 --train_step 400 --epoch_num 100 --initial_lr 0.0001 --val_step 30
Using TensorFlow backend.
train
[['ct10000015.png'], ['ct10000016.png'], ['ct10000017.png'], ['ct10000018.png'], ['ct10000019.png'], ['ct10000020.png'], ['ct10000021.png'], ['ct10000022.png'], ['ct10000023.png'], ['ct10000024.png'], ['ct10000025.png'], ['ct20000004.png'], ['ct20000005.png'], ['ct20000006.png'], ['ct20000007.png'], ['ct20000008.png'], ['ct20000009.png'], ['ct20000010.png'], ['ct20000011.png'], ['ct20000012.png'], ['ct30000003.png'], ['ct30000004.png'], ['ct30000005.png'], ['ct30000006.png'], ['ct30000007.png'], ['ct30000008.png'], ['ct30000009.png'], ['ct30000010.png'], ['ct30000011.png'], ['ct30000012.png']]
new train
[['ct40000006.png'], ['ct90000008.png'], ['ct90000005.png'], ['ct90000002.png'], ['ct90000001.png'], ['ct90000000.png'], ['ct40000000.png'], ['ct40000007.png'], ['ct40000001.png'], ['ct90000007.png'], ['ct40000003.png'], ['ct90000003.png'], ['ct90000006.png'], ['ct90000009.png'], ['ct90000004.png'], ['ct40000005.png']]
new taiin
[['ct40000006.png'], ['ct90000008.png'], ['ct90000005.png'], ['ct90000002.png'], ['ct90000001.png'], ['ct90000000.png'], ['ct40000000.png'], ['ct40000007.png'], ['ct40000001.png'], ['ct90000007.png'], ['ct40000003.png'], ['ct90000003.png'], ['ct90000006.png'], ['ct90000009.png'], ['ct90000004.png'], ['ct40000005.png']]
validation
[['ct40000004.png'], ['ct40000002.png'], ['ct10000017.png'], ['ct20000010.png'], ['ct10000016.png']]
(512, 512, 1)
WARNING:tensorflow:From /home/tomoharu/forGCE/capsule_layers.py:355: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead
WARNING:tensorflow:From /home/tomoharu/forGCE/capsule_layers.py:384: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
__________________________________________________________________________________________________
Layer (type)                         Output Shape              Param #   Connected to             
==================================================================================================
input_1 (InputLayer)                 (None, 512, 512, 1)       0                                  
__________________________________________________________________________________________________
conv1 (Conv2D)                       (None, 512, 512, 16)      416       input_1[0][0]            
__________________________________________________________________________________________________
reshape_1 (Reshape)                  (None, 512, 512, 1, 16)   0         conv1[0][0]              
__________________________________________________________________________________________________
primarycaps (ConvCapsuleLayer)       (None, 256, 256, 2, 16)   12832     reshape_1[0][0]          
__________________________________________________________________________________________________
conv_cap_2_1 (ConvCapsuleLayer)      (None, 256, 256, 4, 16)   25664     primarycaps[0][0]        
__________________________________________________________________________________________________
conv_cap_2_2 (ConvCapsuleLayer)      (None, 128, 128, 4, 32)   51328     conv_cap_2_1[0][0]       
__________________________________________________________________________________________________
conv_cap_3_1 (ConvCapsuleLayer)      (None, 128, 128, 8, 32)   205056    conv_cap_2_2[0][0]       
__________________________________________________________________________________________________
conv_cap_3_2 (ConvCapsuleLayer)      (None, 64, 64, 8, 64)     410112    conv_cap_3_1[0][0]       
__________________________________________________________________________________________________
conv_cap_4_1 (ConvCapsuleLayer)      (None, 64, 64, 8, 32)     409856    conv_cap_3_2[0][0]       
__________________________________________________________________________________________________
deconv_cap_1_1 (DeconvCapsuleLayer)  (None, 128, 128, 8, 32)   131328    conv_cap_4_1[0][0]       
__________________________________________________________________________________________________
up_1 (Concatenate)                   (None, 128, 128, 16, 32)  0         deconv_cap_1_1[0][0]     
                                                                         conv_cap_3_1[0][0]       
__________________________________________________________________________________________________
deconv_cap_1_2 (ConvCapsuleLayer)    (None, 128, 128, 4, 32)   102528    up_1[0][0]               
__________________________________________________________________________________________________
deconv_cap_2_1 (DeconvCapsuleLayer)  (None, 256, 256, 4, 16)   32832     deconv_cap_1_2[0][0]     
__________________________________________________________________________________________________
up_2 (Concatenate)                   (None, 256, 256, 8, 16)   0         deconv_cap_2_1[0][0]     
                                                                         conv_cap_2_1[0][0]       
__________________________________________________________________________________________________
deconv_cap_2_2 (ConvCapsuleLayer)    (None, 256, 256, 4, 16)   25664     up_2[0][0]               
__________________________________________________________________________________________________
deconv_cap_3_1 (DeconvCapsuleLayer)  (None, 512, 512, 2, 16)   8224      deconv_cap_2_2[0][0]     
__________________________________________________________________________________________________
up_3 (Concatenate)                   (None, 512, 512, 3, 16)   0         deconv_cap_3_1[0][0]     
                                                                         reshape_1[0][0]          
__________________________________________________________________________________________________
seg_caps (ConvCapsuleLayer)          (None, 512, 512, 1, 16)   272       up_3[0][0]               
__________________________________________________________________________________________________
input_2 (InputLayer)                 (None, 512, 512, 1)       0                                  
__________________________________________________________________________________________________
mask_1 (Mask)                        (None, 512, 512, 1, 16)   0         seg_caps[0][0]           
                                                                         input_2[0][0]            
__________________________________________________________________________________________________
reshape_2 (Reshape)                  (None, 512, 512, 16)      0         mask_1[0][0]             
__________________________________________________________________________________________________
recon_1 (Conv2D)                     (None, 512, 512, 64)      1088      reshape_2[0][0]          
__________________________________________________________________________________________________
recon_2 (Conv2D)                     (None, 512, 512, 128)     8320      recon_1[0][0]            
__________________________________________________________________________________________________
out_seg (Length)                     (None, 512, 512, 1)       0         seg_caps[0][0]           
__________________________________________________________________________________________________
out_recon (Conv2D)                   (None, 512, 512, 1)       129       recon_2[0][0]            
==================================================================================================
Total params: 1,425,649
Trainable params: 1,425,649
Non-trainable params: 0
__________________________________________________________________________________________________
2019-02-13 12:35:57.420077: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-02-13 12:35:58.111222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-02-13 12:35:58.111689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2019-02-13 12:35:58.111720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-02-13 12:35:58.423927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-13 12:35:58.423990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-02-13 12:35:58.424000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-02-13 12:35:58.424317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15129 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
Epoch 1/100
400/400 [==============================] - 216s 541ms/step - loss: 0.4459 - out_seg_loss: 0.3035 - out_recon_loss: 0.1424 - out_seg_dice_hard: 0.0088 - val_loss: 0.3139 - val_out_seg_loss: 0.2421 - val_out_recon_loss: 0.0718 - val_out_seg_dice_hard: 1.7962e-10

Epoch 00001: val_out_seg_dice_hard improved from -inf to 0.00000, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 2/100
400/400 [==============================] - 208s 520ms/step - loss: 0.2978 - out_seg_loss: 0.2573 - out_recon_loss: 0.0405 - out_seg_dice_hard: 1.7782e-10 - val_loss: 0.2472 - val_out_seg_loss: 0.2195 - val_out_recon_loss: 0.0277 - val_out_seg_dice_hard: 1.8187e-10

Epoch 00002: val_out_seg_dice_hard improved from 0.00000 to 0.00000, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 3/100
400/400 [==============================] - 208s 520ms/step - loss: 0.2493 - out_seg_loss: 0.2201 - out_recon_loss: 0.0292 - out_seg_dice_hard: 1.7247e-10 - val_loss: 0.1855 - val_out_seg_loss: 0.1648 - val_out_recon_loss: 0.0207 - val_out_seg_dice_hard: 1.7255e-10

Epoch 00003: val_out_seg_dice_hard did not improve from 0.00000
Epoch 4/100
400/400 [==============================] - 208s 520ms/step - loss: 0.1713 - out_seg_loss: 0.1453 - out_recon_loss: 0.0260 - out_seg_dice_hard: 0.5030 - val_loss: 0.0972 - val_out_seg_loss: 0.0807 - val_out_recon_loss: 0.0165 - val_out_seg_dice_hard: 0.8878

Epoch 00004: val_out_seg_dice_hard improved from 0.00000 to 0.88779, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 5/100
400/400 [==============================] - 208s 520ms/step - loss: 0.1262 - out_seg_loss: 0.1006 - out_recon_loss: 0.0256 - out_seg_dice_hard: 0.8249 - val_loss: 0.0877 - val_out_seg_loss: 0.0696 - val_out_recon_loss: 0.0181 - val_out_seg_dice_hard: 0.8908

Epoch 00005: val_out_seg_dice_hard improved from 0.88779 to 0.89083, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 6/100
400/400 [==============================] - 208s 520ms/step - loss: 0.1262 - out_seg_loss: 0.1012 - out_recon_loss: 0.0250 - out_seg_dice_hard: 0.8154 - val_loss: 0.0820 - val_out_seg_loss: 0.0651 - val_out_recon_loss: 0.0169 - val_out_seg_dice_hard: 0.8559

Epoch 00006: val_out_seg_dice_hard did not improve from 0.89083
Epoch 7/100
400/400 [==============================] - 208s 520ms/step - loss: 0.1112 - out_seg_loss: 0.0868 - out_recon_loss: 0.0244 - out_seg_dice_hard: 0.8408 - val_loss: 0.0780 - val_out_seg_loss: 0.0605 - val_out_recon_loss: 0.0175 - val_out_seg_dice_hard: 0.9021

Epoch 00007: val_out_seg_dice_hard improved from 0.89083 to 0.90211, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 8/100
400/400 [==============================] - 208s 520ms/step - loss: 0.1061 - out_seg_loss: 0.0820 - out_recon_loss: 0.0241 - out_seg_dice_hard: 0.8450 - val_loss: 0.0741 - val_out_seg_loss: 0.0555 - val_out_recon_loss: 0.0186 - val_out_seg_dice_hard: 0.8806

Epoch 00008: val_out_seg_dice_hard did not improve from 0.90211
Epoch 9/100
400/400 [==============================] - 208s 520ms/step - loss: 0.1047 - out_seg_loss: 0.0799 - out_recon_loss: 0.0248 - out_seg_dice_hard: 0.8436 - val_loss: 0.0715 - val_out_seg_loss: 0.0530 - val_out_recon_loss: 0.0186 - val_out_seg_dice_hard: 0.8787

Epoch 00009: val_out_seg_dice_hard did not improve from 0.90211
Epoch 10/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0961 - out_seg_loss: 0.0723 - out_recon_loss: 0.0238 - out_seg_dice_hard: 0.8610 - val_loss: 0.0616 - val_out_seg_loss: 0.0454 - val_out_recon_loss: 0.0162 - val_out_seg_dice_hard: 0.9016

Epoch 00010: val_out_seg_dice_hard did not improve from 0.90211
Epoch 11/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0933 - out_seg_loss: 0.0696 - out_recon_loss: 0.0237 - out_seg_dice_hard: 0.8655 - val_loss: 0.0604 - val_out_seg_loss: 0.0457 - val_out_recon_loss: 0.0147 - val_out_seg_dice_hard: 0.9110

Epoch 00011: val_out_seg_dice_hard improved from 0.90211 to 0.91096, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 12/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0882 - out_seg_loss: 0.0645 - out_recon_loss: 0.0237 - out_seg_dice_hard: 0.8801 - val_loss: 0.0629 - val_out_seg_loss: 0.0473 - val_out_recon_loss: 0.0155 - val_out_seg_dice_hard: 0.9126

Epoch 00012: val_out_seg_dice_hard improved from 0.91096 to 0.91262, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 13/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0886 - out_seg_loss: 0.0654 - out_recon_loss: 0.0232 - out_seg_dice_hard: 0.8814 - val_loss: 0.0634 - val_out_seg_loss: 0.0473 - val_out_recon_loss: 0.0161 - val_out_seg_dice_hard: 0.9160

Epoch 00013: val_out_seg_dice_hard improved from 0.91262 to 0.91600, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 14/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0854 - out_seg_loss: 0.0625 - out_recon_loss: 0.0229 - out_seg_dice_hard: 0.8863 - val_loss: 0.0580 - val_out_seg_loss: 0.0416 - val_out_recon_loss: 0.0164 - val_out_seg_dice_hard: 0.9104

Epoch 00014: val_out_seg_dice_hard did not improve from 0.91600
Epoch 15/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0815 - out_seg_loss: 0.0589 - out_recon_loss: 0.0226 - out_seg_dice_hard: 0.8947 - val_loss: 0.0589 - val_out_seg_loss: 0.0442 - val_out_recon_loss: 0.0147 - val_out_seg_dice_hard: 0.9193

Epoch 00015: val_out_seg_dice_hard improved from 0.91600 to 0.91931, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 16/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0833 - out_seg_loss: 0.0600 - out_recon_loss: 0.0233 - out_seg_dice_hard: 0.8893 - val_loss: 0.0912 - val_out_seg_loss: 0.0692 - val_out_recon_loss: 0.0219 - val_out_seg_dice_hard: 0.7618

Epoch 00016: val_out_seg_dice_hard did not improve from 0.91931
Epoch 17/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0859 - out_seg_loss: 0.0624 - out_recon_loss: 0.0235 - out_seg_dice_hard: 0.8906 - val_loss: 0.0586 - val_out_seg_loss: 0.0420 - val_out_recon_loss: 0.0166 - val_out_seg_dice_hard: 0.9095

Epoch 00017: val_out_seg_dice_hard did not improve from 0.91931
Epoch 18/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0812 - out_seg_loss: 0.0576 - out_recon_loss: 0.0236 - out_seg_dice_hard: 0.9008 - val_loss: 0.0600 - val_out_seg_loss: 0.0441 - val_out_recon_loss: 0.0160 - val_out_seg_dice_hard: 0.8968

Epoch 00018: val_out_seg_dice_hard did not improve from 0.91931
Epoch 19/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0792 - out_seg_loss: 0.0562 - out_recon_loss: 0.0231 - out_seg_dice_hard: 0.8972 - val_loss: 0.0582 - val_out_seg_loss: 0.0406 - val_out_recon_loss: 0.0176 - val_out_seg_dice_hard: 0.9046

Epoch 00019: val_out_seg_dice_hard did not improve from 0.91931
Epoch 20/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0776 - out_seg_loss: 0.0538 - out_recon_loss: 0.0239 - out_seg_dice_hard: 0.9057 - val_loss: 0.0523 - val_out_seg_loss: 0.0382 - val_out_recon_loss: 0.0141 - val_out_seg_dice_hard: 0.9095

Epoch 00020: val_out_seg_dice_hard did not improve from 0.91931

Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.
Epoch 21/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0713 - out_seg_loss: 0.0482 - out_recon_loss: 0.0231 - out_seg_dice_hard: 0.9152 - val_loss: 0.0513 - val_out_seg_loss: 0.0370 - val_out_recon_loss: 0.0143 - val_out_seg_dice_hard: 0.9249

Epoch 00021: val_out_seg_dice_hard improved from 0.91931 to 0.92486, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 22/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0743 - out_seg_loss: 0.0505 - out_recon_loss: 0.0238 - out_seg_dice_hard: 0.9144 - val_loss: 0.0527 - val_out_seg_loss: 0.0389 - val_out_recon_loss: 0.0138 - val_out_seg_dice_hard: 0.9201

Epoch 00022: val_out_seg_dice_hard did not improve from 0.92486
Epoch 23/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0725 - out_seg_loss: 0.0492 - out_recon_loss: 0.0233 - out_seg_dice_hard: 0.9150 - val_loss: 0.0501 - val_out_seg_loss: 0.0354 - val_out_recon_loss: 0.0147 - val_out_seg_dice_hard: 0.9276

Epoch 00023: val_out_seg_dice_hard improved from 0.92486 to 0.92765, saving model to ./ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Epoch 24/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0724 - out_seg_loss: 0.0491 - out_recon_loss: 0.0233 - out_seg_dice_hard: 0.9149 - val_loss: 0.0497 - val_out_seg_loss: 0.0361 - val_out_recon_loss: 0.0136 - val_out_seg_dice_hard: 0.9251

Epoch 00024: val_out_seg_dice_hard did not improve from 0.92765
Epoch 25/100
400/400 [==============================] - 208s 520ms/step - loss: 0.0726 - out_seg_loss: 0.0487 - out_recon_loss: 0.0239 - out_seg_dice_hard: 0.9159 - val_loss: 0.0540 - val_out_seg_loss: 0.0373 - val_out_recon_loss: 0.0167 - val_out_seg_dice_hard: 0.9253

Epoch 00025: val_out_seg_dice_hard did not improve from 0.92765
Epoch 26/100
119/400 [=======>......................] - ETA: 2:22 - loss: 0.0716 - out_seg_loss: 0.0489 - out_recon_loss: 0.0226 - out_seg_dice_hard: 0.9135^CTraceback (most recent call last):
  File "main.py", line 235, in <module>
    main(arguments)
  File "main.py", line 82, in main
    train(args, train_list, val_list, model_list[0], net_input_shape)
  File "/home/tomoharu/forGCE/train.py", line 169, in train
    callbacks=callbacks, verbose=args.verbose)
  File "/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File "/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py", line 217, in fit_generator
    class_weight=class_weight)
  File "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py", line 1217, in train_on_batch
    outputs = self.train_function(ins)
  File "/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    return self._call(inputs)
  File "/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1439, in __call__
    run_metadata_ptr)
KeyboardInterrupt
tomoharu@tensorflow-1-vm:~/forGCE$ python3 main.py --data_root_dir ./ct --split_num 1 --net segcapsr3 --train 0 --test 1 --manip 0 --save_prefix valaug_ --which_gpus -1 --gpus 1 --train_step 400 --epoch_num 100 --initial_lr 0.0001 --val_step 30 --weights_path saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
Using TensorFlow backend.
train
[['ct10000015.png'], ['ct10000016.png'], ['ct10000017.png'], ['ct10000018.png'], ['ct10000019.png'], ['ct10000020.png'], ['ct10000021.png'], ['ct10000022.png'], ['ct10000023.png'], ['ct10000024.png'], ['ct10000025.png'], ['ct20000004.png'], ['ct20000005.png'], ['ct20000006.png'], ['ct20000007.png'], ['ct20000008.png'], ['ct20000009.png'], ['ct20000010.png'], ['ct20000011.png'], ['ct20000012.png'], ['ct30000003.png'], ['ct30000004.png'], ['ct30000005.png'], ['ct30000006.png'], ['ct30000007.png'], ['ct30000008.png'], ['ct30000009.png'], ['ct30000010.png'], ['ct30000011.png'], ['ct30000012.png']]
new train
[['ct40000006.png'], ['ct90000008.png'], ['ct90000005.png'], ['ct90000002.png'], ['ct90000001.png'], ['ct90000000.png'], ['ct40000000.png'], ['ct40000007.png'], ['ct40000001.png'], ['ct90000007.png'], ['ct40000003.png'], ['ct90000003.png'], ['ct90000006.png'], ['ct90000009.png'], ['ct90000004.png'], ['ct40000005.png']]
new taiin
[['ct40000006.png'], ['ct90000008.png'], ['ct90000005.png'], ['ct90000002.png'], ['ct90000001.png'], ['ct90000000.png'], ['ct40000000.png'], ['ct40000007.png'], ['ct40000001.png'], ['ct90000007.png'], ['ct40000003.png'], ['ct90000003.png'], ['ct90000006.png'], ['ct90000009.png'], ['ct90000004.png'], ['ct40000005.png']]
validation
[['ct40000004.png'], ['ct40000002.png'], ['ct10000017.png'], ['ct20000010.png'], ['ct10000016.png']]
(512, 512, 1)
WARNING:tensorflow:From /home/tomoharu/forGCE/capsule_layers.py:355: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead
WARNING:tensorflow:From /home/tomoharu/forGCE/capsule_layers.py:384: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
__________________________________________________________________________________________________
Layer (type)                         Output Shape              Param #   Connected to             
==================================================================================================
input_1 (InputLayer)                 (None, 512, 512, 1)       0                                  
__________________________________________________________________________________________________
conv1 (Conv2D)                       (None, 512, 512, 16)      416       input_1[0][0]            
__________________________________________________________________________________________________
reshape_1 (Reshape)                  (None, 512, 512, 1, 16)   0         conv1[0][0]              
__________________________________________________________________________________________________
primarycaps (ConvCapsuleLayer)       (None, 256, 256, 2, 16)   12832     reshape_1[0][0]          
__________________________________________________________________________________________________
conv_cap_2_1 (ConvCapsuleLayer)      (None, 256, 256, 4, 16)   25664     primarycaps[0][0]        
__________________________________________________________________________________________________
conv_cap_2_2 (ConvCapsuleLayer)      (None, 128, 128, 4, 32)   51328     conv_cap_2_1[0][0]       
__________________________________________________________________________________________________
conv_cap_3_1 (ConvCapsuleLayer)      (None, 128, 128, 8, 32)   205056    conv_cap_2_2[0][0]       
__________________________________________________________________________________________________
conv_cap_3_2 (ConvCapsuleLayer)      (None, 64, 64, 8, 64)     410112    conv_cap_3_1[0][0]       
__________________________________________________________________________________________________
conv_cap_4_1 (ConvCapsuleLayer)      (None, 64, 64, 8, 32)     409856    conv_cap_3_2[0][0]       
__________________________________________________________________________________________________
deconv_cap_1_1 (DeconvCapsuleLayer)  (None, 128, 128, 8, 32)   131328    conv_cap_4_1[0][0]       
__________________________________________________________________________________________________
up_1 (Concatenate)                   (None, 128, 128, 16, 32)  0         deconv_cap_1_1[0][0]     
                                                                         conv_cap_3_1[0][0]       
__________________________________________________________________________________________________
deconv_cap_1_2 (ConvCapsuleLayer)    (None, 128, 128, 4, 32)   102528    up_1[0][0]               
__________________________________________________________________________________________________
deconv_cap_2_1 (DeconvCapsuleLayer)  (None, 256, 256, 4, 16)   32832     deconv_cap_1_2[0][0]     
__________________________________________________________________________________________________
up_2 (Concatenate)                   (None, 256, 256, 8, 16)   0         deconv_cap_2_1[0][0]     
                                                                         conv_cap_2_1[0][0]       
__________________________________________________________________________________________________
deconv_cap_2_2 (ConvCapsuleLayer)    (None, 256, 256, 4, 16)   25664     up_2[0][0]               
__________________________________________________________________________________________________
deconv_cap_3_1 (DeconvCapsuleLayer)  (None, 512, 512, 2, 16)   8224      deconv_cap_2_2[0][0]     
__________________________________________________________________________________________________
up_3 (Concatenate)                   (None, 512, 512, 3, 16)   0         deconv_cap_3_1[0][0]     
                                                                         reshape_1[0][0]          
__________________________________________________________________________________________________
seg_caps (ConvCapsuleLayer)          (None, 512, 512, 1, 16)   272       up_3[0][0]               
__________________________________________________________________________________________________
input_2 (InputLayer)                 (None, 512, 512, 1)       0                                  
__________________________________________________________________________________________________
mask_1 (Mask)                        (None, 512, 512, 1, 16)   0         seg_caps[0][0]           
                                                                         input_2[0][0]            
__________________________________________________________________________________________________
reshape_2 (Reshape)                  (None, 512, 512, 16)      0         mask_1[0][0]             
__________________________________________________________________________________________________
recon_1 (Conv2D)                     (None, 512, 512, 64)      1088      reshape_2[0][0]          
__________________________________________________________________________________________________
recon_2 (Conv2D)                     (None, 512, 512, 128)     8320      recon_1[0][0]            
__________________________________________________________________________________________________
out_seg (Length)                     (None, 512, 512, 1)       0         seg_caps[0][0]           
__________________________________________________________________________________________________
out_recon (Conv2D)                   (None, 512, 512, 1)       129       recon_2[0][0]            
==================================================================================================
Total params: 1,425,649
Trainable params: 1,425,649
Non-trainable params: 0
__________________________________________________________________________________________________
2019-02-13 14:05:27.161642: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-02-13 14:05:28.354156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-02-13 14:05:28.354748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2019-02-13 14:05:28.354811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-02-13 14:05:28.678225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-13 14:05:28.678283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-02-13 14:05:28.678298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-02-13 14:05:28.678699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15129 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
__________________________________________________________________________________________________
Layer (type)                         Output Shape              Param #   Connected to             
==================================================================================================
input_1 (InputLayer)                 (None, 512, 512, 1)       0                                  
__________________________________________________________________________________________________
conv1 (Conv2D)                       (None, 512, 512, 16)      416       input_1[0][0]            
__________________________________________________________________________________________________
reshape_1 (Reshape)                  (None, 512, 512, 1, 16)   0         conv1[0][0]              
__________________________________________________________________________________________________
primarycaps (ConvCapsuleLayer)       (None, 256, 256, 2, 16)   12832     reshape_1[0][0]          
__________________________________________________________________________________________________
conv_cap_2_1 (ConvCapsuleLayer)      (None, 256, 256, 4, 16)   25664     primarycaps[0][0]        
__________________________________________________________________________________________________
conv_cap_2_2 (ConvCapsuleLayer)      (None, 128, 128, 4, 32)   51328     conv_cap_2_1[0][0]       
__________________________________________________________________________________________________
conv_cap_3_1 (ConvCapsuleLayer)      (None, 128, 128, 8, 32)   205056    conv_cap_2_2[0][0]       
__________________________________________________________________________________________________
conv_cap_3_2 (ConvCapsuleLayer)      (None, 64, 64, 8, 64)     410112    conv_cap_3_1[0][0]       
__________________________________________________________________________________________________
conv_cap_4_1 (ConvCapsuleLayer)      (None, 64, 64, 8, 32)     409856    conv_cap_3_2[0][0]       
__________________________________________________________________________________________________
deconv_cap_1_1 (DeconvCapsuleLayer)  (None, 128, 128, 8, 32)   131328    conv_cap_4_1[0][0]       
__________________________________________________________________________________________________
up_1 (Concatenate)                   (None, 128, 128, 16, 32)  0         deconv_cap_1_1[0][0]     
                                                                         conv_cap_3_1[0][0]       
__________________________________________________________________________________________________
deconv_cap_1_2 (ConvCapsuleLayer)    (None, 128, 128, 4, 32)   102528    up_1[0][0]               
__________________________________________________________________________________________________
deconv_cap_2_1 (DeconvCapsuleLayer)  (None, 256, 256, 4, 16)   32832     deconv_cap_1_2[0][0]     
__________________________________________________________________________________________________
up_2 (Concatenate)                   (None, 256, 256, 8, 16)   0         deconv_cap_2_1[0][0]     
                                                                         conv_cap_2_1[0][0]       
__________________________________________________________________________________________________
deconv_cap_2_2 (ConvCapsuleLayer)    (None, 256, 256, 4, 16)   25664     up_2[0][0]               
__________________________________________________________________________________________________
deconv_cap_3_1 (DeconvCapsuleLayer)  (None, 512, 512, 2, 16)   8224      deconv_cap_2_2[0][0]     
__________________________________________________________________________________________________
up_3 (Concatenate)                   (None, 512, 512, 3, 16)   0         deconv_cap_3_1[0][0]     
                                                                         reshape_1[0][0]          
__________________________________________________________________________________________________
seg_caps (ConvCapsuleLayer)          (None, 512, 512, 1, 16)   272       up_3[0][0]               
__________________________________________________________________________________________________
mask_2 (Mask)                        (None, 512, 512, 1, 16)   0         seg_caps[0][0]           
__________________________________________________________________________________________________
reshape_3 (Reshape)                  (None, 512, 512, 16)      0         mask_2[0][0]             
__________________________________________________________________________________________________
recon_1 (Conv2D)                     (None, 512, 512, 64)      1088      reshape_3[0][0]          
__________________________________________________________________________________________________
recon_2 (Conv2D)                     (None, 512, 512, 128)     8320      recon_1[0][0]            
__________________________________________________________________________________________________
out_seg (Length)                     (None, 512, 512, 1)       0         seg_caps[0][0]           
__________________________________________________________________________________________________
out_recon (Conv2D)                   (None, 512, 512, 1)       129       recon_2[0][0]            
==================================================================================================
Total params: 1,425,649
Trainable params: 1,425,649
Non-trainable params: 0
__________________________________________________________________________________________________
Testing... This will take some time...
1/1 [==============================] - 2s 2s/step                                                                     | 0/16 [00:00<?, ?it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4525371193885803
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9311719431530825
Computing Jaccard
	Jaccard: 0.8712083643276304
1/1 [==============================] - 0s 264ms/step                                                          | 1/16 [00:02<00:31,  2.11s/it]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4450274109840393
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.8963713931831735
Computing Jaccard
	Jaccard: 0.8122038407182642
1/1 [==============================] - 0s 325ms/step                                                          | 2/16 [00:02<00:22,  1.57s/it]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4449690580368042
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.8991988270408965
Computing Jaccard
	Jaccard: 0.8168585291599277
1/1 [==============================] - 0s 215ms/step                                                          | 3/16 [00:02<00:15,  1.22s/it]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4562748074531555
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9370883326805995
Computing Jaccard
	Jaccard: 0.8816239029945736
1/1 [==============================] - 0s 250ms/step                                                          | 4/16 [00:03<00:11,  1.07it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4561622440814972
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.952274091276779
Computing Jaccard
	Jaccard: 0.908896194461048
1/1 [==============================] - 0s 286ms/step                                                          | 5/16 [00:03<00:08,  1.33it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.45985734462738037
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.949754619553621
Computing Jaccard
	Jaccard: 0.9043168741670188
1/1 [==============================] - 0s 319ms/step                                                          | 6/16 [00:03<00:06,  1.57it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.456531822681427
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9012316913460225
Computing Jaccard
	Jaccard: 0.8202199537863055
1/1 [==============================] - 0s 313ms/step                                                          | 7/16 [00:04<00:05,  1.77it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.43388229608535767
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9012052262664527
Computing Jaccard
	Jaccard: 0.8201761127824502
1/1 [==============================] - 1s 612ms/step█████▌                                                    | 8/16 [00:04<00:04,  1.91it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4600925147533417
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9352399627758575
Computing Jaccard
	Jaccard: 0.8783574984782981
1/1 [==============================] - 0s 322ms/step████████████                                              | 9/16 [00:05<00:04,  1.73it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.44145482778549194
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9261485272063285
Computing Jaccard
	Jaccard: 0.8624549583164538
1/1 [==============================] - 0s 241ms/step██████████████████                                       | 10/16 [00:05<00:03,  1.90it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4562216103076935
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9245014757756821
Computing Jaccard
	Jaccard: 0.8596027376629461
1/1 [==============================] - 0s 231ms/step████████████████████████▌                                | 11/16 [00:06<00:02,  2.09it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4524782598018646
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9222111822005962
Computing Jaccard
	Jaccard: 0.8556510950666001
1/1 [==============================] - 0s 279ms/step███████████████████████████████                          | 12/16 [00:06<00:01,  2.33it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.44141778349876404
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.898569143458159
Computing Jaccard
	Jaccard: 0.815819838459396
1/1 [==============================] - 0s 260ms/step█████████████████████████████████████▌                   | 13/16 [00:06<00:01,  2.38it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.43376868963241577
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9072375890506669
Computing Jaccard
	Jaccard: 0.8302240084031695
1/1 [==============================] - 0s 360ms/step████████████████████████████████████████████             | 14/16 [00:07<00:00,  2.50it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4487256407737732
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9180343547955163
Computing Jaccard
	Jaccard: 0.8484875271820802
1/1 [==============================] - 0s 233ms/step██████████████████████████████████████████████████▌      | 15/16 [00:07<00:00,  2.41it/s]
output
(1, 512, 512)
Segmenting Output
	Threshold: 0.4562666416168213
Saving Output
mask
(512, 512)
Computing Dice
	Dice: 0.9368728204398263
Computing Jaccard
	Jaccard: 0.8812424688713348
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.63it/s]
Done.
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7fd8850e47b8>>
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 738, in __del__
TypeError: 'NoneType' object is not callable
tomoharu@tensorflow-1-vm:~/forGCE$ git add .
tomoharu@tensorflow-1-vm:~/forGCE$ git commit -m 'GCE 2.13 23.57 Sccess Capsule3'
[master 7124bc7] GCE 2.13 23.57 Sccess Capsule3
 8 files changed, 55 insertions(+)
 create mode 100644 ct/logs/segcapsr3/tf_logs/events.out.tfevents.1550059171.tensorflow-1-vm
 create mode 100644 ct/logs/segcapsr3/tf_logs/events.out.tfevents.1550061360.tensorflow-1-vm
 create mode 100644 ct/logs/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_log_2019-02-13-12:35:44.csv
 create mode 100644 ct/logs/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0005_recon-131.072_log_2019-02-13-11:58:37.csv
 create mode 100644 ct/results/segcapsr3/split_1/valaug_dice_jacc_scores.csv
 create mode 100644 ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0001_recon-131.072_model_2019-02-13-12:35:44.hdf5
 create mode 100644 ct/saved_models/segcapsr3/valaug_split-1-batch-1_shuff-1_aug-1_loss-w_bce_strid-1_lr-0.0005_recon-131.072_model_2019-02-13-11:58:37.hdf5
